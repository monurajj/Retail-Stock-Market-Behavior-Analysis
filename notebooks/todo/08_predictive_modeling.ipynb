{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 08 - Predictive Modeling (Planning & Approach)\n",
        "\n",
        "This notebook documents the planned approach for predictive modeling in Phase 3. For Phase 2, we focus on methodology planning and initial model setup.\n",
        "\n",
        "## Objectives\n",
        "- Document predictive modeling approach\n",
        "- Plan time series forecasting models (ARIMA, Prophet)\n",
        "- Plan customer behavior prediction models\n",
        "- Define evaluation metrics\n",
        "- Set up initial data preparation for modeling\n",
        "\n",
        "## Phase 2 Requirements\n",
        "- ✅ Model planning and approach documentation\n",
        "- ✅ Methodology selection and justification\n",
        "- ✅ Evaluation metrics definition\n",
        "- ✅ Data preparation for modeling\n",
        "- ⚠️ Full model implementation (Phase 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (14, 6)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"PREDICTIVE MODELING - PLANNING & APPROACH\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Load data\n",
        "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
        "data_path = os.path.join(project_root, 'data', 'raw', 'Online Retail.csv')\n",
        "\n",
        "df = pd.read_csv(data_path, encoding='latin-1')\n",
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], errors='coerce')\n",
        "df = df[~df['InvoiceNo'].astype(str).str.startswith('C')]\n",
        "df = df[(df['Quantity'] > 0) & (df['UnitPrice'] > 0)]\n",
        "df = df[df['Description'].notna()]\n",
        "df['TotalPrice'] = df['Quantity'] * df['UnitPrice']\n",
        "df = df[df['InvoiceDate'].notna()]\n",
        "\n",
        "print(f\"\\nDataset loaded: {df.shape[0]:,} transactions\")\n",
        "print(f\"Date range: {df['InvoiceDate'].min()} to {df['InvoiceDate'].max()}\")\n",
        "print(f\"\\nNote: This notebook focuses on planning and approach for Phase 3 implementation.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Predictive Modeling Objectives\n",
        "\n",
        "Define the key predictive modeling goals for Phase 3.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Modeling objectives\n",
        "print(\"=\" * 80)\n",
        "print(\"PREDICTIVE MODELING OBJECTIVES\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "objectives = {\n",
        "    \"1. Demand Forecasting\": {\n",
        "        \"Goal\": \"Predict future daily/monthly revenue and transaction volumes\",\n",
        "        \"Use Case\": \"Stock planning, inventory optimization\",\n",
        "        \"Time Horizon\": \"Short-term (1-30 days), Medium-term (1-6 months)\"\n",
        "    },\n",
        "    \"2. Customer Behavior Prediction\": {\n",
        "        \"Goal\": \"Predict customer purchase likelihood and churn risk\",\n",
        "        \"Use Case\": \"Targeted marketing, retention campaigns\",\n",
        "        \"Time Horizon\": \"Next purchase timing, 30/60/90 day churn\"\n",
        "    },\n",
        "    \"3. Product Demand Prediction\": {\n",
        "        \"Goal\": \"Forecast product-level demand\",\n",
        "        \"Use Case\": \"Product-specific stock allocation\",\n",
        "        \"Time Horizon\": \"Weekly and monthly forecasts\"\n",
        "    },\n",
        "    \"4. Basket Size Prediction\": {\n",
        "        \"Goal\": \"Predict transaction value and quantity\",\n",
        "        \"Use Case\": \"Revenue forecasting, pricing strategies\",\n",
        "        \"Time Horizon\": \"Next transaction prediction\"\n",
        "    }\n",
        "}\n",
        "\n",
        "for obj_name, details in objectives.items():\n",
        "    print(f\"\\n{obj_name}:\")\n",
        "    for key, value in details.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Model Selection & Justification\n",
        "\n",
        "Document planned models and justify their selection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model selection\n",
        "print(\"=\" * 80)\n",
        "print(\"MODEL SELECTION & JUSTIFICATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "models = {\n",
        "    \"Time Series Forecasting\": {\n",
        "        \"ARIMA\": {\n",
        "            \"Description\": \"AutoRegressive Integrated Moving Average\",\n",
        "            \"Justification\": \"Handles trend and seasonality, interpretable, good for univariate time series\",\n",
        "            \"Use Case\": \"Daily/monthly revenue forecasting\",\n",
        "            \"Limitations\": \"Requires stationarity, assumes linear relationships\"\n",
        "        },\n",
        "        \"Prophet\": {\n",
        "            \"Description\": \"Facebook's time series forecasting tool\",\n",
        "            \"Justification\": \"Handles seasonality, holidays, trend changes automatically, robust to missing data\",\n",
        "            \"Use Case\": \"Revenue forecasting with multiple seasonality patterns\",\n",
        "            \"Limitations\": \"Less interpretable than ARIMA, requires sufficient historical data\"\n",
        "        }\n",
        "    },\n",
        "    \"Customer Behavior\": {\n",
        "        \"Logistic Regression\": {\n",
        "            \"Description\": \"Binary classification for churn prediction\",\n",
        "            \"Justification\": \"Interpretable, handles categorical features well, baseline model\",\n",
        "            \"Use Case\": \"Customer churn prediction\",\n",
        "            \"Limitations\": \"Assumes linear relationships, may need feature engineering\"\n",
        "        },\n",
        "        \"Random Forest\": {\n",
        "            \"Description\": \"Ensemble method for classification/regression\",\n",
        "            \"Justification\": \"Handles non-linear relationships, feature importance, robust to outliers\",\n",
        "            \"Use Case\": \"Purchase likelihood, basket size prediction\",\n",
        "            \"Limitations\": \"Less interpretable, can overfit with small datasets\"\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "for category, model_dict in models.items():\n",
        "    print(f\"\\n{category}:\")\n",
        "    print(\"=\" * 60)\n",
        "    for model_name, details in model_dict.items():\n",
        "        print(f\"\\n{model_name}:\")\n",
        "        for key, value in details.items():\n",
        "            print(f\"  {key}: {value}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Data Preparation for Modeling\n",
        "\n",
        "Prepare time-series and customer-level datasets for modeling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data preparation\n",
        "print(\"=\" * 80)\n",
        "print(\"DATA PREPARATION FOR MODELING\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# 1. Time-series data for forecasting\n",
        "print(\"\\n1. TIME-SERIES DATA PREPARATION:\")\n",
        "daily_data = df.groupby(df['InvoiceDate'].dt.date).agg({\n",
        "    'TotalPrice': 'sum',\n",
        "    'Quantity': 'sum',\n",
        "    'InvoiceNo': 'nunique',\n",
        "    'CustomerID': 'nunique'\n",
        "}).reset_index()\n",
        "\n",
        "daily_data.columns = ['Date', 'DailyRevenue', 'DailyQuantity', 'DailyTransactions', 'DailyCustomers']\n",
        "daily_data['Date'] = pd.to_datetime(daily_data['Date'])\n",
        "daily_data = daily_data.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "# Create complete date range\n",
        "date_range = pd.date_range(start=daily_data['Date'].min(), end=daily_data['Date'].max(), freq='D')\n",
        "daily_complete = pd.DataFrame({'Date': date_range})\n",
        "daily_complete = daily_complete.merge(daily_data, on='Date', how='left')\n",
        "daily_complete = daily_complete.fillna(0)\n",
        "\n",
        "print(f\"  Daily time-series: {len(daily_complete)} days\")\n",
        "print(f\"  Date range: {daily_complete['Date'].min()} to {daily_complete['Date'].max()}\")\n",
        "print(f\"  Missing days filled: {len(daily_complete) - len(daily_data)}\")\n",
        "\n",
        "# 2. Monthly aggregation\n",
        "monthly_data = df.groupby(df['InvoiceDate'].dt.to_period('M')).agg({\n",
        "    'TotalPrice': 'sum',\n",
        "    'Quantity': 'sum',\n",
        "    'InvoiceNo': 'nunique',\n",
        "    'CustomerID': 'nunique'\n",
        "}).reset_index()\n",
        "\n",
        "monthly_data.columns = ['YearMonth', 'MonthlyRevenue', 'MonthlyQuantity', 'MonthlyTransactions', 'MonthlyCustomers']\n",
        "monthly_data['Date'] = pd.to_datetime(monthly_data['YearMonth'].astype(str))\n",
        "print(f\"\\n  Monthly time-series: {len(monthly_data)} months\")\n",
        "\n",
        "# 3. Customer-level features for behavior prediction\n",
        "print(\"\\n2. CUSTOMER-LEVEL FEATURES:\")\n",
        "reference_date = df['InvoiceDate'].max() + pd.Timedelta(days=1)\n",
        "\n",
        "customer_features = df.groupby('CustomerID').agg({\n",
        "    'InvoiceDate': lambda x: (reference_date - x.max()).days,  # Recency\n",
        "    'InvoiceNo': 'nunique',  # Frequency\n",
        "    'TotalPrice': ['sum', 'mean'],  # Monetary\n",
        "    'Quantity': 'sum',\n",
        "    'InvoiceDate': ['min', 'max']  # First and last purchase\n",
        "}).reset_index()\n",
        "\n",
        "customer_features.columns = ['CustomerID', 'Recency', 'Frequency', 'TotalSpent', 'AvgTransaction', \n",
        "                             'TotalQuantity', 'FirstPurchase', 'LastPurchase']\n",
        "\n",
        "customer_features['CustomerLifetime'] = (customer_features['LastPurchase'] - customer_features['FirstPurchase']).dt.days\n",
        "customer_features['AvgDaysBetweenPurchases'] = customer_features['CustomerLifetime'] / customer_features['Frequency']\n",
        "\n",
        "print(f\"  Customer features: {len(customer_features)} customers\")\n",
        "print(f\"  Features: Recency, Frequency, Monetary, Lifetime, AvgDaysBetweenPurchases\")\n",
        "\n",
        "# Display sample\n",
        "print(\"\\nSample Time-Series Data (Last 10 days):\")\n",
        "print(daily_complete[['Date', 'DailyRevenue', 'DailyTransactions']].tail(10).to_string(index=False))\n",
        "\n",
        "print(\"\\nSample Customer Features (Top 10 by Total Spent):\")\n",
        "print(customer_features.nlargest(10, 'TotalSpent')[['CustomerID', 'Recency', 'Frequency', 'TotalSpent']].to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"DATA PREPARATION COMPLETE\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation metrics\n",
        "print(\"=\" * 80)\n",
        "print(\"EVALUATION METRICS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "metrics = {\n",
        "    \"Time Series Forecasting\": {\n",
        "        \"MAE (Mean Absolute Error)\": \"Average absolute difference between predicted and actual values\",\n",
        "        \"RMSE (Root Mean Squared Error)\": \"Penalizes larger errors more, good for business impact\",\n",
        "        \"MAPE (Mean Absolute Percentage Error)\": \"Percentage error, interpretable for stakeholders\",\n",
        "        \"R² (Coefficient of Determination)\": \"Proportion of variance explained by the model\"\n",
        "    },\n",
        "    \"Classification (Churn/Purchase Prediction)\": {\n",
        "        \"Accuracy\": \"Overall correctness of predictions\",\n",
        "        \"Precision\": \"Proportion of positive predictions that are correct\",\n",
        "        \"Recall\": \"Proportion of actual positives correctly identified\",\n",
        "        \"F1-Score\": \"Harmonic mean of precision and recall\",\n",
        "        \"ROC-AUC\": \"Area under ROC curve, measures classification performance\"\n",
        "    },\n",
        "    \"Regression (Basket Size)\": {\n",
        "        \"MAE\": \"Average absolute error in basket size prediction\",\n",
        "        \"RMSE\": \"Penalizes larger errors\",\n",
        "        \"R²\": \"Model fit quality\"\n",
        "    }\n",
        "}\n",
        "\n",
        "for category, metric_dict in metrics.items():\n",
        "    print(f\"\\n{category}:\")\n",
        "    print(\"-\" * 60)\n",
        "    for metric, description in metric_dict.items():\n",
        "        print(f\"  • {metric}: {description}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Modeling Approach & Implementation Plan\n",
        "\n",
        "Document the step-by-step approach for Phase 3 implementation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implementation plan\n",
        "print(\"=\" * 80)\n",
        "print(\"MODELING APPROACH & IMPLEMENTATION PLAN\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "plan = {\n",
        "    \"Phase 1: Baseline Models\": [\n",
        "        \"1. Implement ARIMA for daily revenue forecasting\",\n",
        "        \"2. Train baseline logistic regression for churn prediction\",\n",
        "        \"3. Evaluate baseline models using defined metrics\",\n",
        "        \"4. Document baseline performance\"\n",
        "    ],\n",
        "    \"Phase 2: Advanced Models\": [\n",
        "        \"1. Implement Prophet for revenue forecasting with seasonality\",\n",
        "        \"2. Train Random Forest for purchase likelihood prediction\",\n",
        "        \"3. Compare advanced models with baselines\",\n",
        "        \"4. Feature engineering and hyperparameter tuning\"\n",
        "    ],\n",
        "    \"Phase 3: Model Validation\": [\n",
        "        \"1. Time-series cross-validation (walk-forward validation)\",\n",
        "        \"2. Hold-out test set evaluation\",\n",
        "        \"3. Statistical significance testing\",\n",
        "        \"4. Business impact assessment\"\n",
        "    ],\n",
        "    \"Phase 4: Model Deployment\": [\n",
        "        \"1. Model serialization and versioning\",\n",
        "        \"2. Prediction pipeline development\",\n",
        "        \"3. Model monitoring framework\",\n",
        "        \"4. Documentation and reporting\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "for phase, steps in plan.items():\n",
        "    print(f\"\\n{phase}:\")\n",
        "    print(\"-\" * 60)\n",
        "    for step in steps:\n",
        "        print(f\"  {step}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"KEY CONSIDERATIONS:\")\n",
        "print(\"=\" * 80)\n",
        "considerations = [\n",
        "    \"Train/Test Split: Use temporal split (e.g., last 3 months as test set)\",\n",
        "    \"Cross-Validation: Time-series cross-validation to avoid data leakage\",\n",
        "    \"Feature Engineering: Create lag features, rolling statistics, temporal features\",\n",
        "    \"Model Interpretability: Balance accuracy with interpretability for business stakeholders\",\n",
        "    \"Scalability: Ensure models can handle production-scale data\",\n",
        "    \"Monitoring: Plan for model performance monitoring and retraining\"\n",
        "]\n",
        "\n",
        "for i, consideration in enumerate(considerations, 1):\n",
        "    print(f\"{i}. {consideration}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PREDICTIVE MODELING PLANNING COMPLETE\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nNext Steps (Phase 3):\")\n",
        "print(\"  1. Implement baseline ARIMA model\")\n",
        "print(\"  2. Implement Prophet model\")\n",
        "print(\"  3. Build customer churn prediction model\")\n",
        "print(\"  4. Evaluate and compare all models\")\n",
        "print(\"  5. Document results and business implications\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
