{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 08 - Predictive Modeling (Planning & Approach)\n",
        "\n",
        "This notebook documents the planned approach for predictive modeling in Phase 3. For Phase 2, we focus on methodology planning and initial model setup.\n",
        "\n",
        "## Objectives\n",
        "- Document predictive modeling approach\n",
        "- Plan time series forecasting models (ARIMA, Prophet)\n",
        "- Plan customer behavior prediction models\n",
        "- Define evaluation metrics\n",
        "- Set up initial data preparation for modeling\n",
        "\n",
        "## Phase 2 Requirements\n",
        "- ✅ Model planning and approach documentation\n",
        "- ✅ Methodology selection and justification\n",
        "- ✅ Evaluation metrics definition\n",
        "- ✅ Data preparation for modeling\n",
        "- ⚠️ Full model implementation (Phase 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (14, 6)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"PREDICTIVE MODELING - PLANNING & APPROACH\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Load data\n",
        "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
        "data_path = os.path.join(project_root, 'data', 'raw', 'Online Retail.csv')\n",
        "\n",
        "df = pd.read_csv(data_path, encoding='latin-1')\n",
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], errors='coerce')\n",
        "df = df[~df['InvoiceNo'].astype(str).str.startswith('C')]\n",
        "df = df[(df['Quantity'] > 0) & (df['UnitPrice'] > 0)]\n",
        "df = df[df['Description'].notna()]\n",
        "df['TotalPrice'] = df['Quantity'] * df['UnitPrice']\n",
        "df = df[df['InvoiceDate'].notna()]\n",
        "\n",
        "print(f\"\\nDataset loaded: {df.shape[0]:,} transactions\")\n",
        "print(f\"Date range: {df['InvoiceDate'].min()} to {df['InvoiceDate'].max()}\")\n",
        "print(f\"\\nNote: This notebook focuses on planning and approach for Phase 3 implementation.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Predictive Modeling Objectives\n",
        "\n",
        "Define the key predictive modeling goals for Phase 3.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Modeling objectives\n",
        "print(\"=\" * 80)\n",
        "print(\"PREDICTIVE MODELING OBJECTIVES\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "objectives = {\n",
        "    \"1. Demand Forecasting\": {\n",
        "        \"Goal\": \"Predict future daily/monthly revenue and transaction volumes\",\n",
        "        \"Use Case\": \"Stock planning, inventory optimization\",\n",
        "        \"Time Horizon\": \"Short-term (1-30 days), Medium-term (1-6 months)\"\n",
        "    },\n",
        "    \"2. Customer Behavior Prediction\": {\n",
        "        \"Goal\": \"Predict customer purchase likelihood and churn risk\",\n",
        "        \"Use Case\": \"Targeted marketing, retention campaigns\",\n",
        "        \"Time Horizon\": \"Next purchase timing, 30/60/90 day churn\"\n",
        "    },\n",
        "    \"3. Product Demand Prediction\": {\n",
        "        \"Goal\": \"Forecast product-level demand\",\n",
        "        \"Use Case\": \"Product-specific stock allocation\",\n",
        "        \"Time Horizon\": \"Weekly and monthly forecasts\"\n",
        "    },\n",
        "    \"4. Basket Size Prediction\": {\n",
        "        \"Goal\": \"Predict transaction value and quantity\",\n",
        "        \"Use Case\": \"Revenue forecasting, pricing strategies\",\n",
        "        \"Time Horizon\": \"Next transaction prediction\"\n",
        "    }\n",
        "}\n",
        "\n",
        "for obj_name, details in objectives.items():\n",
        "    print(f\"\\n{obj_name}:\")\n",
        "    for key, value in details.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Model Selection & Justification\n",
        "\n",
        "Document planned models and justify their selection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model selection\n",
        "print(\"=\" * 80)\n",
        "print(\"MODEL SELECTION & JUSTIFICATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "models = {\n",
        "    \"Time Series Forecasting\": {\n",
        "        \"ARIMA\": {\n",
        "            \"Description\": \"AutoRegressive Integrated Moving Average\",\n",
        "            \"Justification\": \"Handles trend and seasonality, interpretable, good for univariate time series\",\n",
        "            \"Use Case\": \"Daily/monthly revenue forecasting\",\n",
        "            \"Limitations\": \"Requires stationarity, assumes linear relationships\"\n",
        "        },\n",
        "        \"Prophet\": {\n",
        "            \"Description\": \"Facebook's time series forecasting tool\",\n",
        "            \"Justification\": \"Handles seasonality, holidays, trend changes automatically, robust to missing data\",\n",
        "            \"Use Case\": \"Revenue forecasting with multiple seasonality patterns\",\n",
        "            \"Limitations\": \"Less interpretable than ARIMA, requires sufficient historical data\"\n",
        "        }\n",
        "    },\n",
        "    \"Customer Behavior\": {\n",
        "        \"Logistic Regression\": {\n",
        "            \"Description\": \"Binary classification for churn prediction\",\n",
        "            \"Justification\": \"Interpretable, handles categorical features well, baseline model\",\n",
        "            \"Use Case\": \"Customer churn prediction\",\n",
        "            \"Limitations\": \"Assumes linear relationships, may need feature engineering\"\n",
        "        },\n",
        "        \"Random Forest\": {\n",
        "            \"Description\": \"Ensemble method for classification/regression\",\n",
        "            \"Justification\": \"Handles non-linear relationships, feature importance, robust to outliers\",\n",
        "            \"Use Case\": \"Purchase likelihood, basket size prediction\",\n",
        "            \"Limitations\": \"Less interpretable, can overfit with small datasets\"\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "for category, model_dict in models.items():\n",
        "    print(f\"\\n{category}:\")\n",
        "    print(\"=\" * 60)\n",
        "    for model_name, details in model_dict.items():\n",
        "        print(f\"\\n{model_name}:\")\n",
        "        for key, value in details.items():\n",
        "            print(f\"  {key}: {value}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Data Preparation for Modeling\n",
        "\n",
        "Prepare time-series and customer-level datasets for modeling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data preparation\n",
        "print(\"=\" * 80)\n",
        "print(\"DATA PREPARATION FOR MODELING\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# 1. Time-series data for forecasting\n",
        "print(\"\\n1. TIME-SERIES DATA PREPARATION:\")\n",
        "daily_data = df.groupby(df['InvoiceDate'].dt.date).agg({\n",
        "    'TotalPrice': 'sum',\n",
        "    'Quantity': 'sum',\n",
        "    'InvoiceNo': 'nunique',\n",
        "    'CustomerID': 'nunique'\n",
        "}).reset_index()\n",
        "\n",
        "daily_data.columns = ['Date', 'DailyRevenue', 'DailyQuantity', 'DailyTransactions', 'DailyCustomers']\n",
        "daily_data['Date'] = pd.to_datetime(daily_data['Date'])\n",
        "daily_data = daily_data.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "# Create complete date range\n",
        "date_range = pd.date_range(start=daily_data['Date'].min(), end=daily_data['Date'].max(), freq='D')\n",
        "daily_complete = pd.DataFrame({'Date': date_range})\n",
        "daily_complete = daily_complete.merge(daily_data, on='Date', how='left')\n",
        "daily_complete = daily_complete.fillna(0)\n",
        "\n",
        "print(f\"  Daily time-series: {len(daily_complete)} days\")\n",
        "print(f\"  Date range: {daily_complete['Date'].min()} to {daily_complete['Date'].max()}\")\n",
        "print(f\"  Missing days filled: {len(daily_complete) - len(daily_data)}\")\n",
        "\n",
        "# 2. Monthly aggregation\n",
        "monthly_data = df.groupby(df['InvoiceDate'].dt.to_period('M')).agg({\n",
        "    'TotalPrice': 'sum',\n",
        "    'Quantity': 'sum',\n",
        "    'InvoiceNo': 'nunique',\n",
        "    'CustomerID': 'nunique'\n",
        "}).reset_index()\n",
        "\n",
        "monthly_data.columns = ['YearMonth', 'MonthlyRevenue', 'MonthlyQuantity', 'MonthlyTransactions', 'MonthlyCustomers']\n",
        "monthly_data['Date'] = pd.to_datetime(monthly_data['YearMonth'].astype(str))\n",
        "print(f\"\\n  Monthly time-series: {len(monthly_data)} months\")\n",
        "\n",
        "# 3. Customer-level features for behavior prediction\n",
        "print(\"\\n2. CUSTOMER-LEVEL FEATURES:\")\n",
        "reference_date = df['InvoiceDate'].max() + pd.Timedelta(days=1)\n",
        "\n",
        "customer_features = df.groupby('CustomerID').agg({\n",
        "    'InvoiceDate': lambda x: (reference_date - x.max()).days,  # Recency\n",
        "    'InvoiceNo': 'nunique',  # Frequency\n",
        "    'TotalPrice': ['sum', 'mean'],  # Monetary\n",
        "    'Quantity': 'sum',\n",
        "    'InvoiceDate': ['min', 'max']  # First and last purchase\n",
        "}).reset_index()\n",
        "\n",
        "customer_features.columns = ['CustomerID', 'Recency', 'Frequency', 'TotalSpent', 'AvgTransaction', \n",
        "                             'TotalQuantity', 'FirstPurchase', 'LastPurchase']\n",
        "\n",
        "customer_features['CustomerLifetime'] = (customer_features['LastPurchase'] - customer_features['FirstPurchase']).dt.days\n",
        "customer_features['AvgDaysBetweenPurchases'] = customer_features['CustomerLifetime'] / customer_features['Frequency']\n",
        "\n",
        "print(f\"  Customer features: {len(customer_features)} customers\")\n",
        "print(f\"  Features: Recency, Frequency, Monetary, Lifetime, AvgDaysBetweenPurchases\")\n",
        "\n",
        "# Display sample\n",
        "print(\"\\nSample Time-Series Data (Last 10 days):\")\n",
        "print(daily_complete[['Date', 'DailyRevenue', 'DailyTransactions']].tail(10).to_string(index=False))\n",
        "\n",
        "print(\"\\nSample Customer Features (Top 10 by Total Spent):\")\n",
        "print(customer_features.nlargest(10, 'TotalSpent')[['CustomerID', 'Recency', 'Frequency', 'TotalSpent']].to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"DATA PREPARATION COMPLETE\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation metrics\n",
        "print(\"=\" * 80)\n",
        "print(\"EVALUATION METRICS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "metrics = {\n",
        "    \"Time Series Forecasting\": {\n",
        "        \"MAE (Mean Absolute Error)\": \"Average absolute difference between predicted and actual values\",\n",
        "        \"RMSE (Root Mean Squared Error)\": \"Penalizes larger errors more, good for business impact\",\n",
        "        \"MAPE (Mean Absolute Percentage Error)\": \"Percentage error, interpretable for stakeholders\",\n",
        "        \"R² (Coefficient of Determination)\": \"Proportion of variance explained by the model\"\n",
        "    },\n",
        "    \"Classification (Churn/Purchase Prediction)\": {\n",
        "        \"Accuracy\": \"Overall correctness of predictions\",\n",
        "        \"Precision\": \"Proportion of positive predictions that are correct\",\n",
        "        \"Recall\": \"Proportion of actual positives correctly identified\",\n",
        "        \"F1-Score\": \"Harmonic mean of precision and recall\",\n",
        "        \"ROC-AUC\": \"Area under ROC curve, measures classification performance\"\n",
        "    },\n",
        "    \"Regression (Basket Size)\": {\n",
        "        \"MAE\": \"Average absolute error in basket size prediction\",\n",
        "        \"RMSE\": \"Penalizes larger errors\",\n",
        "        \"R²\": \"Model fit quality\"\n",
        "    }\n",
        "}\n",
        "\n",
        "for category, metric_dict in metrics.items():\n",
        "    print(f\"\\n{category}:\")\n",
        "    print(\"-\" * 60)\n",
        "    for metric, description in metric_dict.items():\n",
        "        print(f\"  • {metric}: {description}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Modeling Approach & Implementation Plan\n",
        "\n",
        "Document the step-by-step approach for Phase 3 implementation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implementation plan\n",
        "print(\"=\" * 80)\n",
        "print(\"MODELING APPROACH & IMPLEMENTATION PLAN\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "plan = {\n",
        "    \"Phase 1: Baseline Models\": [\n",
        "        \"1. Implement ARIMA for daily revenue forecasting\",\n",
        "        \"2. Train baseline logistic regression for churn prediction\",\n",
        "        \"3. Evaluate baseline models using defined metrics\",\n",
        "        \"4. Document baseline performance\"\n",
        "    ],\n",
        "    \"Phase 2: Advanced Models\": [\n",
        "        \"1. Implement Prophet for revenue forecasting with seasonality\",\n",
        "        \"2. Train Random Forest for purchase likelihood prediction\",\n",
        "        \"3. Compare advanced models with baselines\",\n",
        "        \"4. Feature engineering and hyperparameter tuning\"\n",
        "    ],\n",
        "    \"Phase 3: Model Validation\": [\n",
        "        \"1. Time-series cross-validation (walk-forward validation)\",\n",
        "        \"2. Hold-out test set evaluation\",\n",
        "        \"3. Statistical significance testing\",\n",
        "        \"4. Business impact assessment\"\n",
        "    ],\n",
        "    \"Phase 4: Model Deployment\": [\n",
        "        \"1. Model serialization and versioning\",\n",
        "        \"2. Prediction pipeline development\",\n",
        "        \"3. Model monitoring framework\",\n",
        "        \"4. Documentation and reporting\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "for phase, steps in plan.items():\n",
        "    print(f\"\\n{phase}:\")\n",
        "    print(\"-\" * 60)\n",
        "    for step in steps:\n",
        "        print(f\"  {step}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"KEY CONSIDERATIONS:\")\n",
        "print(\"=\" * 80)\n",
        "considerations = [\n",
        "    \"Train/Test Split: Use temporal split (e.g., last 3 months as test set)\",\n",
        "    \"Cross-Validation: Time-series cross-validation to avoid data leakage\",\n",
        "    \"Feature Engineering: Create lag features, rolling statistics, temporal features\",\n",
        "    \"Model Interpretability: Balance accuracy with interpretability for business stakeholders\",\n",
        "    \"Scalability: Ensure models can handle production-scale data\",\n",
        "    \"Monitoring: Plan for model performance monitoring and retraining\"\n",
        "]\n",
        "\n",
        "for i, consideration in enumerate(considerations, 1):\n",
        "    print(f\"{i}. {consideration}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PREDICTIVE MODELING PLANNING COMPLETE\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nNext Steps (Phase 3):\")\n",
        "print(\"  1. Implement baseline ARIMA model\")\n",
        "print(\"  2. Implement Prophet model\")\n",
        "print(\"  3. Build customer churn prediction model\")\n",
        "print(\"  4. Evaluate and compare all models\")\n",
        "print(\"  5. Document results and business implications\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Data Visualization for Modeling Preparation\n",
        "\n",
        "Visualize prepared datasets to understand their characteristics for modeling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize prepared datasets\n",
        "print(\"=\" * 80)\n",
        "print(\"DATA VISUALIZATION FOR MODELING PREPARATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# 1. Time-series data visualization\n",
        "fig, axes = plt.subplots(3, 2, figsize=(16, 18))\n",
        "fig.suptitle('Predictive Modeling - Data Preparation Visualization', fontsize=16, y=0.995)\n",
        "\n",
        "# Daily revenue time-series\n",
        "axes[0, 0].plot(daily_complete['Date'], daily_complete['DailyRevenue'], \n",
        "               linewidth=1.5, color='steelblue', alpha=0.7)\n",
        "axes[0, 0].set_xlabel('Date', fontsize=12)\n",
        "axes[0, 0].set_ylabel('Daily Revenue (£)', fontsize=12)\n",
        "axes[0, 0].set_title('Daily Revenue Time-Series', fontweight='bold')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Monthly revenue time-series\n",
        "axes[0, 1].plot(monthly_data['Date'], monthly_data['MonthlyRevenue'], \n",
        "               marker='o', linewidth=2, markersize=6, color='coral')\n",
        "axes[0, 1].set_xlabel('Date', fontsize=12)\n",
        "axes[0, 1].set_ylabel('Monthly Revenue (£)', fontsize=12)\n",
        "axes[0, 1].set_title('Monthly Revenue Time-Series', fontweight='bold')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Daily revenue distribution\n",
        "axes[1, 0].hist(daily_complete['DailyRevenue'], bins=50, edgecolor='black', alpha=0.7, color='teal')\n",
        "axes[1, 0].set_xlabel('Daily Revenue (£)', fontsize=12)\n",
        "axes[1, 0].set_ylabel('Frequency', fontsize=12)\n",
        "axes[1, 0].set_title('Daily Revenue Distribution', fontweight='bold')\n",
        "axes[1, 0].axvline(x=daily_complete['DailyRevenue'].mean(), color='red', linestyle='--', \n",
        "                  linewidth=2, label=f'Mean: £{daily_complete[\"DailyRevenue\"].mean():,.0f}')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Monthly revenue distribution\n",
        "axes[1, 1].hist(monthly_data['MonthlyRevenue'], bins=20, edgecolor='black', alpha=0.7, color='purple')\n",
        "axes[1, 1].set_xlabel('Monthly Revenue (£)', fontsize=12)\n",
        "axes[1, 1].set_ylabel('Frequency', fontsize=12)\n",
        "axes[1, 1].set_title('Monthly Revenue Distribution', fontweight='bold')\n",
        "axes[1, 1].axvline(x=monthly_data['MonthlyRevenue'].mean(), color='red', linestyle='--',\n",
        "                  linewidth=2, label=f'Mean: £{monthly_data[\"MonthlyRevenue\"].mean():,.0f}')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Customer features distribution\n",
        "axes[2, 0].scatter(customer_features['Recency'], customer_features['Frequency'],\n",
        "                  c=customer_features['TotalSpent'], cmap='viridis', alpha=0.6, s=20, edgecolors='black', linewidth=0.3)\n",
        "axes[2, 0].set_xlabel('Recency (days)', fontsize=12)\n",
        "axes[2, 0].set_ylabel('Frequency (transactions)', fontsize=12)\n",
        "axes[2, 0].set_title('Customer Features: Recency vs Frequency\\n(Color = Total Spent)', fontweight='bold')\n",
        "axes[2, 0].set_xscale('log')\n",
        "axes[2, 0].set_yscale('log')\n",
        "axes[2, 0].grid(True, alpha=0.3)\n",
        "cbar = plt.colorbar(axes[2, 0].collections[0], ax=axes[2, 0])\n",
        "cbar.set_label('Total Spent (£)', fontsize=10)\n",
        "\n",
        "# Customer monetary value distribution\n",
        "axes[2, 1].hist(customer_features['TotalSpent'], bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
        "axes[2, 1].set_xlabel('Total Spent (£)', fontsize=12)\n",
        "axes[2, 1].set_ylabel('Frequency', fontsize=12)\n",
        "axes[2, 1].set_title('Customer Monetary Value Distribution', fontweight='bold')\n",
        "axes[2, 1].set_xscale('log')\n",
        "axes[2, 1].axvline(x=customer_features['TotalSpent'].median(), color='red', linestyle='--',\n",
        "                  linewidth=2, label=f'Median: £{customer_features[\"TotalSpent\"].median():,.0f}')\n",
        "axes[2, 1].legend()\n",
        "axes[2, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 2. Summary statistics visualization\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "fig.suptitle('Data Summary Statistics', fontsize=14, y=1.02)\n",
        "\n",
        "# Time-series statistics comparison\n",
        "ts_stats = pd.DataFrame({\n",
        "    'Metric': ['Mean', 'Median', 'Std', 'Min', 'Max'],\n",
        "    'Daily Revenue': [\n",
        "        daily_complete['DailyRevenue'].mean(),\n",
        "        daily_complete['DailyRevenue'].median(),\n",
        "        daily_complete['DailyRevenue'].std(),\n",
        "        daily_complete['DailyRevenue'].min(),\n",
        "        daily_complete['DailyRevenue'].max()\n",
        "    ],\n",
        "    'Monthly Revenue': [\n",
        "        monthly_data['MonthlyRevenue'].mean(),\n",
        "        monthly_data['MonthlyRevenue'].median(),\n",
        "        monthly_data['MonthlyRevenue'].std(),\n",
        "        monthly_data['MonthlyRevenue'].min(),\n",
        "        monthly_data['MonthlyRevenue'].max()\n",
        "    ]\n",
        "})\n",
        "\n",
        "x_pos = np.arange(len(ts_stats))\n",
        "width = 0.35\n",
        "axes[0].bar(x_pos - width/2, ts_stats['Daily Revenue'], width, label='Daily', alpha=0.7, color='steelblue', edgecolor='black')\n",
        "axes[0].bar(x_pos + width/2, ts_stats['Monthly Revenue'], width, label='Monthly', alpha=0.7, color='coral', edgecolor='black')\n",
        "axes[0].set_xlabel('Statistic', fontsize=12)\n",
        "axes[0].set_ylabel('Value (£)', fontsize=12)\n",
        "axes[0].set_title('Time-Series Statistics Comparison', fontweight='bold')\n",
        "axes[0].set_xticks(x_pos)\n",
        "axes[0].set_xticklabels(ts_stats['Metric'], rotation=45)\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3, axis='y')\n",
        "axes[0].set_yscale('log')\n",
        "\n",
        "# Customer feature statistics\n",
        "customer_stats = pd.DataFrame({\n",
        "    'Feature': ['Recency', 'Frequency', 'Total Spent'],\n",
        "    'Mean': [\n",
        "        customer_features['Recency'].mean(),\n",
        "        customer_features['Frequency'].mean(),\n",
        "        customer_features['TotalSpent'].mean()\n",
        "    ],\n",
        "    'Median': [\n",
        "        customer_features['Recency'].median(),\n",
        "        customer_features['Frequency'].median(),\n",
        "        customer_features['TotalSpent'].median()\n",
        "    ]\n",
        "})\n",
        "\n",
        "x_pos = np.arange(len(customer_stats))\n",
        "axes[1].bar(x_pos - width/2, customer_stats['Mean'], width, label='Mean', alpha=0.7, color='teal', edgecolor='black')\n",
        "axes[1].bar(x_pos + width/2, customer_stats['Median'], width, label='Median', alpha=0.7, color='purple', edgecolor='black')\n",
        "axes[1].set_xlabel('Feature', fontsize=12)\n",
        "axes[1].set_ylabel('Value', fontsize=12)\n",
        "axes[1].set_title('Customer Feature Statistics', fontweight='bold')\n",
        "axes[1].set_xticks(x_pos)\n",
        "axes[1].set_xticklabels(customer_stats['Feature'], rotation=45)\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3, axis='y')\n",
        "axes[1].set_yscale('log')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"DATA VISUALIZATION COMPLETE\")\n",
        "print(\"=\" * 80)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
