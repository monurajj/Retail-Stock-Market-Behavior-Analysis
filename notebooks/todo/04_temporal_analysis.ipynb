{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04 - Temporal Pattern Analysis\n",
        "\n",
        "This notebook performs comprehensive temporal analysis including time-series decomposition to understand purchase patterns across different time dimensions.\n",
        "\n",
        "## Objectives\n",
        "- Perform time-series decomposition (trend, seasonality, residuals)\n",
        "- Analyze purchase patterns by hour of day\n",
        "- Analyze purchase patterns by day of week\n",
        "- Analyze purchase patterns by month\n",
        "- Identify peak purchase times\n",
        "- Visualize temporal trends and decomposition components\n",
        "- Statistical analysis of temporal patterns\n",
        "\n",
        "## Phase 2 Requirements\n",
        "- ✅ Time-series decomposition (trend, seasonality, residuals)\n",
        "- ✅ Temporal pattern identification\n",
        "- ✅ Statistical validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (14, 6)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"TEMPORAL PATTERN ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Load data\n",
        "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
        "data_path = os.path.join(project_root, 'data', 'raw', 'Online Retail.csv')\n",
        "\n",
        "df = pd.read_csv(data_path, encoding='latin-1')\n",
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], errors='coerce')\n",
        "df = df[~df['InvoiceNo'].astype(str).str.startswith('C')]\n",
        "df = df[(df['Quantity'] > 0) & (df['UnitPrice'] > 0)]\n",
        "df = df[df['Description'].notna()]\n",
        "df['TotalPrice'] = df['Quantity'] * df['UnitPrice']\n",
        "df = df[df['InvoiceDate'].notna()]\n",
        "\n",
        "print(f\"\\nDataset loaded: {df.shape[0]:,} transactions\")\n",
        "print(f\"Date range: {df['InvoiceDate'].min()} to {df['InvoiceDate'].max()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Prepare Time-Series Data\n",
        "\n",
        "Aggregate transaction data by date for time-series analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggregate by date for time-series\n",
        "daily_data = df.groupby(df['InvoiceDate'].dt.date).agg({\n",
        "    'TotalPrice': ['sum', 'mean', 'count'],\n",
        "    'Quantity': 'sum',\n",
        "    'InvoiceNo': 'nunique',\n",
        "    'CustomerID': 'nunique'\n",
        "}).reset_index()\n",
        "\n",
        "daily_data.columns = ['Date', 'DailyRevenue', 'AvgTransactionValue', 'TransactionCount', \n",
        "                      'TotalQuantity', 'UniqueInvoices', 'UniqueCustomers']\n",
        "daily_data['Date'] = pd.to_datetime(daily_data['Date'])\n",
        "daily_data = daily_data.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "# Create complete date range to handle missing dates\n",
        "date_range = pd.date_range(start=daily_data['Date'].min(), end=daily_data['Date'].max(), freq='D')\n",
        "daily_complete = pd.DataFrame({'Date': date_range})\n",
        "daily_complete = daily_complete.merge(daily_data, on='Date', how='left')\n",
        "daily_complete = daily_complete.fillna(0)  # Fill missing dates with 0\n",
        "\n",
        "# Set Date as index for time-series analysis\n",
        "ts_data = daily_complete.set_index('Date')['DailyRevenue']\n",
        "\n",
        "print(f\"\\nTime-series prepared:\")\n",
        "print(f\"  Total days: {len(ts_data)}\")\n",
        "print(f\"  Days with transactions: {len(daily_data)}\")\n",
        "print(f\"  Missing days: {len(ts_data) - len(daily_data)}\")\n",
        "print(f\"\\nTime-series statistics:\")\n",
        "print(ts_data.describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Time-Series Decomposition\n",
        "\n",
        "Decompose the time-series into trend, seasonality, and residuals components.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform time-series decomposition\n",
        "# Using multiplicative model (better for retail data with increasing variance)\n",
        "# Period = 7 for weekly seasonality\n",
        "print(\"=\" * 80)\n",
        "print(\"TIME-SERIES DECOMPOSITION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Remove zeros for decomposition (replace with small value)\n",
        "ts_for_decomp = ts_data.copy()\n",
        "ts_for_decomp = ts_for_decomp.replace(0, np.nan).interpolate(method='linear')\n",
        "\n",
        "# Perform decomposition with weekly seasonality (period=7)\n",
        "decomposition = seasonal_decompose(ts_for_decomp, model='multiplicative', period=7, extrapolate_trend='freq')\n",
        "\n",
        "# Extract components\n",
        "trend = decomposition.trend\n",
        "seasonal = decomposition.seasonal\n",
        "residual = decomposition.resid\n",
        "\n",
        "print(\"\\nDecomposition Components:\")\n",
        "print(f\"  Trend - Mean: £{trend.mean():,.2f}, Std: £{trend.std():,.2f}\")\n",
        "print(f\"  Seasonal - Mean: {seasonal.mean():.4f}, Std: {seasonal.std():.4f}\")\n",
        "print(f\"  Residual - Mean: {residual.mean():.4f}, Std: {residual.std():.4f}\")\n",
        "\n",
        "# Visualize decomposition\n",
        "fig, axes = plt.subplots(4, 1, figsize=(16, 14))\n",
        "fig.suptitle('Time-Series Decomposition: Trend, Seasonality, and Residuals', fontsize=16, y=0.995)\n",
        "\n",
        "# Original time-series\n",
        "axes[0].plot(ts_for_decomp.index, ts_for_decomp.values, color='steelblue', linewidth=1.5)\n",
        "axes[0].set_title('Original Time-Series (Daily Revenue)', fontweight='bold')\n",
        "axes[0].set_ylabel('Revenue (£)')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Trend component\n",
        "axes[1].plot(trend.index, trend.values, color='darkgreen', linewidth=2)\n",
        "axes[1].set_title('Trend Component', fontweight='bold')\n",
        "axes[1].set_ylabel('Revenue (£)')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# Seasonal component\n",
        "axes[2].plot(seasonal.index, seasonal.values, color='coral', linewidth=1.5, alpha=0.7)\n",
        "axes[2].set_title('Seasonal Component (Weekly Pattern)', fontweight='bold')\n",
        "axes[2].set_ylabel('Seasonal Factor')\n",
        "axes[2].axhline(y=1.0, color='red', linestyle='--', linewidth=1)\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "# Residual component\n",
        "axes[3].plot(residual.index, residual.values, color='purple', linewidth=1, alpha=0.7)\n",
        "axes[3].set_title('Residual Component (Random Fluctuations)', fontweight='bold')\n",
        "axes[3].set_ylabel('Residual')\n",
        "axes[3].set_xlabel('Date')\n",
        "axes[3].axhline(y=1.0, color='red', linestyle='--', linewidth=1)\n",
        "axes[3].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Statistical analysis of components\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"DECOMPOSITION STATISTICS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nTrend Analysis:\")\n",
        "print(f\"  Trend direction: {'Increasing' if trend.iloc[-1] > trend.iloc[0] else 'Decreasing'}\")\n",
        "print(f\"  Trend change: £{trend.iloc[-1] - trend.iloc[0]:,.2f}\")\n",
        "print(f\"  Average trend: £{trend.mean():,.2f}\")\n",
        "\n",
        "print(\"\\nSeasonal Analysis:\")\n",
        "print(f\"  Seasonal strength: {seasonal.std():.4f}\")\n",
        "print(f\"  Max seasonal factor: {seasonal.max():.4f} (day {seasonal.idxmax().day_name()})\")\n",
        "print(f\"  Min seasonal factor: {seasonal.min():.4f} (day {seasonal.idxmin().day_name()})\")\n",
        "\n",
        "print(\"\\nResidual Analysis:\")\n",
        "print(f\"  Residual mean: {residual.mean():.4f} (should be ~1.0 for multiplicative)\")\n",
        "print(f\"  Residual std: {residual.std():.4f}\")\n",
        "print(f\"  Residual range: [{residual.min():.4f}, {residual.max():.4f}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test for stationarity\n",
        "print(\"=\" * 80)\n",
        "print(\"STATIONARITY TESTING\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "def adf_test(timeseries):\n",
        "    \"\"\"Perform Augmented Dickey-Fuller test\"\"\"\n",
        "    result = adfuller(timeseries.dropna())\n",
        "    print(f\"\\nADF Statistic: {result[0]:.4f}\")\n",
        "    print(f\"p-value: {result[1]:.4f}\")\n",
        "    print(f\"Critical Values:\")\n",
        "    for key, value in result[4].items():\n",
        "        print(f\"  {key}: {value:.4f}\")\n",
        "    \n",
        "    if result[1] <= 0.05:\n",
        "        print(\"\\n✓ Series is STATIONARY (p-value <= 0.05)\")\n",
        "        return True\n",
        "    else:\n",
        "        print(\"\\n✗ Series is NON-STATIONARY (p-value > 0.05)\")\n",
        "        return False\n",
        "\n",
        "print(\"\\n1. Original Time-Series:\")\n",
        "is_stationary_original = adf_test(ts_for_decomp)\n",
        "\n",
        "print(\"\\n2. Trend Component:\")\n",
        "is_stationary_trend = adf_test(trend)\n",
        "\n",
        "print(\"\\n3. Residual Component:\")\n",
        "is_stationary_residual = adf_test(residual)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Temporal Pattern Analysis\n",
        "\n",
        "Analyze patterns by hour, day of week, and month.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Temporal pattern analysis\n",
        "print(\"=\" * 80)\n",
        "print(\"TEMPORAL PATTERN ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Hourly patterns\n",
        "df['Hour'] = df['InvoiceDate'].dt.hour\n",
        "hourly_revenue = df.groupby('Hour')['TotalPrice'].sum().sort_index()\n",
        "\n",
        "# Day of week patterns\n",
        "df['DayOfWeek'] = df['InvoiceDate'].dt.dayofweek\n",
        "dow_map = {0: 'Mon', 1: 'Tue', 2: 'Wed', 3: 'Thu', 4: 'Fri', 5: 'Sat', 6: 'Sun'}\n",
        "dow_revenue = df.groupby('DayOfWeek')['TotalPrice'].sum().sort_index()\n",
        "dow_revenue.index = dow_revenue.index.map(dow_map)\n",
        "\n",
        "# Monthly patterns\n",
        "df['Month'] = df['InvoiceDate'].dt.month\n",
        "monthly_revenue = df.groupby('Month')['TotalPrice'].sum().sort_index()\n",
        "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "monthly_revenue.index = [month_names[i-1] for i in monthly_revenue.index]\n",
        "\n",
        "# Visualizations\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "fig.suptitle('Temporal Pattern Analysis', fontsize=16, y=0.995)\n",
        "\n",
        "# Hourly pattern\n",
        "axes[0, 0].bar(hourly_revenue.index, hourly_revenue.values, alpha=0.7, color='steelblue', edgecolor='black')\n",
        "axes[0, 0].set_title('Revenue by Hour of Day', fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Hour')\n",
        "axes[0, 0].set_ylabel('Revenue (£)')\n",
        "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
        "peak_hour = hourly_revenue.idxmax()\n",
        "axes[0, 0].axvline(x=peak_hour, color='red', linestyle='--', label=f'Peak: {peak_hour}:00')\n",
        "axes[0, 0].legend()\n",
        "\n",
        "# Day of week pattern\n",
        "axes[0, 1].bar(range(len(dow_revenue)), dow_revenue.values, alpha=0.7, color='coral', edgecolor='black')\n",
        "axes[0, 1].set_xticks(range(len(dow_revenue)))\n",
        "axes[0, 1].set_xticklabels(dow_revenue.index)\n",
        "axes[0, 1].set_title('Revenue by Day of Week', fontweight='bold')\n",
        "axes[0, 1].set_ylabel('Revenue (£)')\n",
        "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
        "peak_dow = dow_revenue.idxmax()\n",
        "axes[0, 1].axvline(x=list(dow_revenue.index).index(peak_dow), color='red', linestyle='--', label=f'Peak: {peak_dow}')\n",
        "axes[0, 1].legend()\n",
        "\n",
        "# Monthly pattern\n",
        "axes[1, 0].bar(range(len(monthly_revenue)), monthly_revenue.values, alpha=0.7, color='teal', edgecolor='black')\n",
        "axes[1, 0].set_xticks(range(len(monthly_revenue)))\n",
        "axes[1, 0].set_xticklabels(monthly_revenue.index, rotation=45)\n",
        "axes[1, 0].set_title('Revenue by Month', fontweight='bold')\n",
        "axes[1, 0].set_ylabel('Revenue (£)')\n",
        "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
        "peak_month = monthly_revenue.idxmax()\n",
        "axes[1, 0].axvline(x=list(monthly_revenue.index).index(peak_month), color='red', linestyle='--', label=f'Peak: {peak_month}')\n",
        "axes[1, 0].legend()\n",
        "\n",
        "# Daily revenue trend with decomposition overlay\n",
        "axes[1, 1].plot(ts_for_decomp.index, ts_for_decomp.values, alpha=0.5, color='steelblue', label='Original', linewidth=1)\n",
        "axes[1, 1].plot(trend.index, trend.values, color='darkgreen', label='Trend', linewidth=2)\n",
        "axes[1, 1].set_title('Daily Revenue with Trend Component', fontweight='bold')\n",
        "axes[1, 1].set_ylabel('Revenue (£)')\n",
        "axes[1, 1].set_xlabel('Date')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\nPeak Times Identified:\")\n",
        "print(f\"  Peak Hour: {peak_hour}:00 (£{hourly_revenue.max():,.2f})\")\n",
        "print(f\"  Peak Day: {peak_dow} (£{dow_revenue.max():,.2f})\")\n",
        "print(f\"  Peak Month: {peak_month} (£{monthly_revenue.max():,.2f})\")\n",
        "\n",
        "print(\"\\nTemporal Variation:\")\n",
        "print(f\"  Hourly variation: {(hourly_revenue.max() - hourly_revenue.min())/hourly_revenue.mean()*100:.1f}%\")\n",
        "print(f\"  Day-of-week variation: {(dow_revenue.max() - dow_revenue.min())/dow_revenue.mean()*100:.1f}%\")\n",
        "print(f\"  Monthly variation: {(monthly_revenue.max() - monthly_revenue.min())/monthly_revenue.mean()*100:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Autocorrelation Analysis\n",
        "\n",
        "Analyze autocorrelation and partial autocorrelation to identify temporal dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Autocorrelation analysis\n",
        "print(\"=\" * 80)\n",
        "print(\"AUTOCORRELATION ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
        "fig.suptitle('Autocorrelation and Partial Autocorrelation Analysis', fontsize=16, y=0.995)\n",
        "\n",
        "# ACF plot\n",
        "plot_acf(ts_for_decomp.dropna(), lags=30, ax=axes[0], alpha=0.05)\n",
        "axes[0].set_title('Autocorrelation Function (ACF)', fontweight='bold')\n",
        "axes[0].set_xlabel('Lag')\n",
        "axes[0].set_ylabel('Autocorrelation')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# PACF plot\n",
        "plot_pacf(ts_for_decomp.dropna(), lags=30, ax=axes[1], alpha=0.05)\n",
        "axes[1].set_title('Partial Autocorrelation Function (PACF)', fontweight='bold')\n",
        "axes[1].set_xlabel('Lag')\n",
        "axes[1].set_ylabel('Partial Autocorrelation')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate autocorrelation values\n",
        "acf_values = acf(ts_for_decomp.dropna(), nlags=7, fft=True)\n",
        "print(\"\\nAutocorrelation at key lags:\")\n",
        "for lag in [1, 7, 14]:\n",
        "    if lag < len(acf_values):\n",
        "        print(f\"  Lag {lag}: {acf_values[lag]:.4f}\")\n",
        "\n",
        "# Identify significant lags\n",
        "significant_lags = [i for i, val in enumerate(acf_values[1:8]) if abs(val) > 0.2]\n",
        "if significant_lags:\n",
        "    print(f\"\\nSignificant autocorrelation at lags: {[i+1 for i in significant_lags]}\")\n",
        "    print(\"  (Indicates weekly patterns)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Business Insights and Conclusions\n",
        "\n",
        "Interpret temporal patterns for retail stock market behavior.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Business insights\n",
        "print(\"=\" * 80)\n",
        "print(\"BUSINESS INSIGHTS FROM TEMPORAL ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n1. TREND ANALYSIS:\")\n",
        "if trend.iloc[-1] > trend.iloc[0]:\n",
        "    print(\"   - Revenue shows an INCREASING trend over time\")\n",
        "    print(\"   - Indicates business growth or market expansion\")\n",
        "else:\n",
        "    print(\"   - Revenue shows a DECREASING trend over time\")\n",
        "    print(\"   - May indicate market saturation or competitive pressure\")\n",
        "\n",
        "print(\"\\n2. SEASONAL PATTERNS:\")\n",
        "print(f\"   - Strong weekly seasonality detected (seasonal std: {seasonal.std():.4f})\")\n",
        "print(f\"   - Peak day: {peak_dow} - Stock should be optimized for this day\")\n",
        "print(f\"   - Peak hour: {peak_hour}:00 - Staffing and inventory should align\")\n",
        "print(f\"   - Peak month: {peak_month} - Seasonal stock planning critical\")\n",
        "\n",
        "print(\"\\n3. STOCK MANAGEMENT IMPLICATIONS:\")\n",
        "print(\"   - Weekly patterns suggest regular stock replenishment cycles\")\n",
        "print(\"   - Daily patterns inform optimal restocking times\")\n",
        "print(\"   - Monthly patterns guide seasonal inventory planning\")\n",
        "print(\"   - Trend component helps forecast long-term demand\")\n",
        "\n",
        "print(\"\\n4. VOLATILITY INSIGHTS:\")\n",
        "residual_volatility = residual.std()\n",
        "print(f\"   - Residual volatility: {residual_volatility:.4f}\")\n",
        "if residual_volatility > 0.2:\n",
        "    print(\"   - HIGH volatility: Safety stock levels should be increased\")\n",
        "else:\n",
        "    print(\"   - MODERATE volatility: Standard safety stock sufficient\")\n",
        "\n",
        "print(\"\\n5. FORECASTING READINESS:\")\n",
        "if is_stationary_residual:\n",
        "    print(\"   - Residuals are stationary: Good for forecasting models\")\n",
        "else:\n",
        "    print(\"   - Residuals are non-stationary: May need differencing for forecasting\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"TEMPORAL ANALYSIS COMPLETE\")\n",
        "print(\"=\" * 80)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
